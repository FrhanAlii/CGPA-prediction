{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **with Mutaul information**"
      ],
      "metadata": {
        "id": "MeNwmhWjUNRT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T884k2PPHDF",
        "outputId": "5ba1e66d-e52c-41b9-cbe5-95d8da67d670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 features based on mutual information: ['Please provide your current CGPA?', 'Kindly mention your age?', 'Your Fsc/Ics marks percentage?', 'Your matric marks percentage?', 'How many members are in your family?', 'Please mention your NTS score?', 'Do you love your subjects?', 'Do you find your CS/SE subjects difficult?', 'How is your health', 'How much you have interest in this domain']\n",
            "\n",
            "OLS Linear Regression\n",
            "MAE Score:  2.9291999210718305\n",
            "MSE Score:  8.66821960098358\n",
            "RMSE Score:  2.944184029741276\n",
            "R2 Score: -21.98\n",
            "MAPE Score: 110.83\n",
            "\n",
            "Multivariable Linear Regression\n",
            "MAE Score:  0.1327793213332057\n",
            "MSE Score:  0.033546699638289386\n",
            "RMSE Score:  0.18315758143819597\n",
            "R2 Score: 0.91\n",
            "MAPE Score: 5.28\n",
            "\n",
            "Decision Tree Regression\n",
            "MAE Score:  0.1983103448275862\n",
            "MSE Score:  0.10061810344827585\n",
            "RMSE Score:  0.3172035678366116\n",
            "R2 Score: 0.73\n",
            "MAPE Score: 8.42\n",
            "\n",
            "Polynomial Regression\n",
            "MAE Score:  1.7031923190542837\n",
            "MSE Score:  11.729977348085061\n",
            "RMSE Score:  3.424905450970152\n",
            "R2 Score: -30.10\n",
            "MAPE Score: 81.57\n",
            "\n",
            "Random Forest Regression\n",
            "MAE Score:  0.13774827586206898\n",
            "MSE Score:  0.03484589034482758\n",
            "RMSE Score:  0.1866705395739445\n",
            "R2 Score: 0.91\n",
            "MAPE Score: 5.29\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import statsmodels.api as sm\n",
        "import math\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.preprocessing import StandardScaler  # Z-Score Normalization\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('students_responses_main.csv')\n",
        "\n",
        "# Data cleaning and preprocessing\n",
        "df.drop(columns=df.columns[88], inplace=True)\n",
        "df.drop(columns=df.columns[74], inplace=True)\n",
        "df.drop(columns=df.columns[58], inplace=True)\n",
        "df.drop(columns=df.columns[12:50], inplace=True)\n",
        "df.drop(columns=df.columns[10], inplace=True)\n",
        "df.drop(columns=df.columns[8], inplace=True)\n",
        "df.drop(columns=df.columns[7], inplace=True)\n",
        "df.drop(columns=df.columns[0], inplace=True)\n",
        "\n",
        "# Modify the semester column\n",
        "df['Kindly choose your current semester.'] = (\n",
        "    df['Kindly choose your current semester.']\n",
        "    .str.replace('2 Semester', '1 Semester', regex=True)\n",
        "    .str.replace('3 Semester', '2 Semester', regex=True)\n",
        "    .str.replace('4 Semester', '3 Semester', regex=True)\n",
        "    .str.replace('5 Semester', '4 Semester', regex=True)\n",
        "    .str.replace('6 Semester', '5 Semester', regex=True)\n",
        "    .str.replace('7 Semester', '6 Semester', regex=True)\n",
        "    .str.replace('8 Semester', '7 Semester', regex=True)\n",
        ")\n",
        "\n",
        "# Fix the matric and Fsc/Ics marks\n",
        "df['Your matric marks percentage?'] = np.where(\n",
        "    df['Your matric marks percentage?'] > 100,\n",
        "    df['Your matric marks percentage?'] * 100 / 1100,\n",
        "    df['Your matric marks percentage?'],\n",
        ")\n",
        "\n",
        "df[\"Your Fsc/Ics marks percentage?\"] = np.where(\n",
        "    df[\"Your Fsc/Ics marks percentage?\"] > 100,\n",
        "    df[\"Your Fsc/Ics marks percentage?\"] * 100 / 1100,\n",
        "    df[\"Your Fsc/Ics marks percentage?\"],\n",
        ")\n",
        "\n",
        "df.round(decimals=2)\n",
        "\n",
        "# Handle outliers using IQR method\n",
        "df = df.select_dtypes(include=['number'])\n",
        "Q1 = df.quantile(0.15)\n",
        "Q3 = df.quantile(0.85)\n",
        "IQR = Q3 - Q1\n",
        "df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# Factorize categorical columns\n",
        "def factorize_fun(data):\n",
        "    obj_cols = data.loc[:, data.dtypes == object].columns\n",
        "    for col in obj_cols:\n",
        "        data[col] = pd.factorize(data[col])[0] + 1\n",
        "    return data\n",
        "\n",
        "df = factorize_fun(df)\n",
        "\n",
        "# Impute missing values using KNN\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "def knn_null(df):\n",
        "    imputer = KNNImputer(n_neighbors=2)\n",
        "    df1 = imputer.fit_transform(df)\n",
        "    df2 = pd.DataFrame(df1, columns=df.columns)\n",
        "    return df2\n",
        "\n",
        "df = knn_null(df)\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = df.drop(columns=['Please mention your Previous Semester GPA?'])\n",
        "y = df['Please mention your Previous Semester GPA?']\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred, clip_threshold=1.0):\n",
        "    # Clip the values in y_true to avoid division by very small numbers (close to 0)\n",
        "    y_true_clipped = np.clip(y_true, clip_threshold, np.inf)  # Clip values below `clip_threshold`\n",
        "    return np.mean(np.abs((y_true_clipped - y_pred) / y_true_clipped)) * 100\n",
        "\n",
        "# Z-Score Normalization\n",
        "def zscore_normalize(df):\n",
        "    scaler = StandardScaler()\n",
        "    data_scaled = scaler.fit_transform(df)\n",
        "    return pd.DataFrame(data_scaled, columns=df.columns)\n",
        "\n",
        "X = zscore_normalize(X)\n",
        "\n",
        "# Mutual Information feature selection\n",
        "def mutual_info(X, y, top_k=10):\n",
        "    mi = mutual_info_regression(X, y)\n",
        "    mi_series = pd.Series(mi, index=X.columns)\n",
        "    top_features = mi_series.nlargest(top_k).index\n",
        "    print(f\"Top {top_k} features based on mutual information: {list(top_features)}\")\n",
        "    return X[top_features]\n",
        "\n",
        "X_new = mutual_info(X, y, top_k=10)\n",
        "\n",
        "# Train-test split with selected features\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.1, random_state=4)\n",
        "\n",
        "# Remaining regression and evaluation steps remain unchanged\n",
        "\n",
        "\n",
        "# Evaluation Metrics\n",
        "def evaluate_model(y_test, y_pred):\n",
        "    print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "    print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "    print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "    print(\"R2 Score: %.2f\" % r2_score(y_test, y_pred))\n",
        "    print(\"MAPE Score: %.2f\" % (np.mean(np.abs((y_test - y_pred) / np.clip(y_test, 1e-8, np.inf))) * 100))\n",
        "\n",
        "# Linear Regression\n",
        "print(\"\\nOLS Linear Regression\")\n",
        "model = sm.OLS(endog=y_train, exog=X_train).fit()\n",
        "y_pred = model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred)\n",
        "\n",
        "print(\"\\nMultivariable Linear Regression\")\n",
        "regression = LinearRegression()\n",
        "model = regression.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred)\n",
        "\n",
        "# Decision Tree Regression\n",
        "print(\"\\nDecision Tree Regression\")\n",
        "regressor = DecisionTreeRegressor(random_state=0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred)\n",
        "\n",
        "# Polynomial Regression\n",
        "print(\"\\nPolynomial Regression\")\n",
        "poly_reg = PolynomialFeatures(degree=4)\n",
        "X_poly = poly_reg.fit_transform(X_train)\n",
        "regressor = LinearRegression()\n",
        "model = regressor.fit(X_poly, y_train)\n",
        "y_pred = model.predict(poly_reg.transform(X_test))\n",
        "evaluate_model(y_test, y_pred)\n",
        "\n",
        "# Random Forest Regression\n",
        "print(\"\\nRandom Forest Regression\")\n",
        "regressor = RandomForestRegressor(n_estimators=10, random_state=0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **with CHI-Square**"
      ],
      "metadata": {
        "id": "U0n_NrkGUXNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import statsmodels.api as sm\n",
        "import math\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.preprocessing import StandardScaler  # Z-Score Normalization\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('students_responses_main.csv')\n",
        "df_org = df.copy()\n",
        "\n",
        "# Data cleaning steps\n",
        "df.drop(columns=df.columns[88], inplace=True)\n",
        "df.drop(columns=df.columns[74], inplace=True)\n",
        "df.drop(columns=df.columns[58], inplace=True)\n",
        "df.drop(columns=df.columns[12:50], inplace=True)\n",
        "df.drop(columns=df.columns[10], inplace=True)\n",
        "df.drop(columns=df.columns[8], inplace=True)\n",
        "df.drop(columns=df.columns[7], inplace=True)\n",
        "df.drop(columns=df.columns[0], inplace=True)\n",
        "\n",
        "# Modify the semester column\n",
        "df['Kindly choose your current semester.'] = (\n",
        "    df['Kindly choose your current semester.']\n",
        "    .str.replace('2 Semester', '1 Semester', regex=True)\n",
        "    .str.replace('3 Semester', '2 Semester', regex=True)\n",
        "    .str.replace('4 Semester', '3 Semester', regex=True)\n",
        "    .str.replace('5 Semester', '4 Semester', regex=True)\n",
        "    .str.replace('6 Semester', '5 Semester', regex=True)\n",
        "    .str.replace('7 Semester', '6 Semester', regex=True)\n",
        "    .str.replace('8 Semester', '7 Semester', regex=True)\n",
        ")\n",
        "\n",
        "# Fix the matric and Fsc/Ics marks\n",
        "df['Your matric marks percentage?'] = np.where(\n",
        "    df['Your matric marks percentage?'] > 100,\n",
        "    df['Your matric marks percentage?'] * 100 / 1100,\n",
        "    df['Your matric marks percentage?'],\n",
        ")\n",
        "\n",
        "df[\"Your Fsc/Ics marks percentage?\"] = np.where(\n",
        "    df[\"Your Fsc/Ics marks percentage?\"] > 100,\n",
        "    df[\"Your Fsc/Ics marks percentage?\"] * 100 / 1100,\n",
        "    df[\"Your Fsc/Ics marks percentage?\"],\n",
        ")\n",
        "\n",
        "df.round(decimals=2)\n",
        "\n",
        "# Handle outliers using IQR method\n",
        "df = df.select_dtypes(include=['number'])\n",
        "Q1 = df.quantile(0.15)\n",
        "Q3 = df.quantile(0.85)\n",
        "IQR = Q3 - Q1\n",
        "df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# Factorize categorical columns\n",
        "def factorize_fun(data):\n",
        "    obj_cols = data.loc[:, data.dtypes == object].columns\n",
        "    for col in obj_cols:\n",
        "        data[col] = pd.factorize(data[col])[0] + 1\n",
        "    return data\n",
        "\n",
        "df = factorize_fun(df)\n",
        "\n",
        "# Impute missing values using KNN\n",
        "def knn_null(df):\n",
        "    imputer = KNNImputer(n_neighbors=2)\n",
        "    df1 = imputer.fit_transform(df)\n",
        "    df2 = pd.DataFrame(df1, columns=df.columns)\n",
        "    return df2\n",
        "\n",
        "df = knn_null(df)\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = df.drop(columns=['Please mention your Previous Semester GPA?'])\n",
        "y = df['Please mention your Previous Semester GPA?']\n",
        "\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred, clip_threshold=1.0):\n",
        "    # Clip the values in y_true to avoid division by very small numbers (close to 0)\n",
        "    y_true_clipped = np.clip(y_true, clip_threshold, np.inf)  # Clip values below `clip_threshold`\n",
        "    return np.mean(np.abs((y_true_clipped - y_pred) / y_true_clipped)) * 100\n",
        "# Z-Score Normalization\n",
        "def zscore_normalize(df):\n",
        "    scaler = StandardScaler()\n",
        "    data_scaled = scaler.fit_transform(df)\n",
        "    return pd.DataFrame(data_scaled, columns=df.columns)\n",
        "\n",
        "X = zscore_normalize(X)\n",
        "\n",
        "# Ensure non-negative values after Z-score normalization\n",
        "def ensure_non_negative(df):\n",
        "    min_val = df.min().min()\n",
        "    if min_val < 0:\n",
        "        df = df - min_val  # Shift all values to make them non-negative\n",
        "    return df\n",
        "\n",
        "# Apply Z-Score normalization and then ensure non-negative values\n",
        "X = ensure_non_negative(X)\n",
        "\n",
        "# Discretize the target variable to make it categorical\n",
        "def discretize_target(y, n_bins=5):\n",
        "    discretizer = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
        "    y_discretized = discretizer.fit_transform(y.values.reshape(-1, 1))\n",
        "    return y_discretized.flatten()  # Flatten the array to avoid shape issues\n",
        "\n",
        "y_discretized = discretize_target(y)\n",
        "\n",
        "# Chi-Square feature selection\n",
        "def chi_square_selection(X, y, k=10):\n",
        "    chi2_selector = SelectKBest(chi2, k=k)\n",
        "    X_new = chi2_selector.fit_transform(X, y)\n",
        "    selected_columns = X.columns[chi2_selector.get_support()]\n",
        "    print(f\"Selected features after Chi-Square test: {selected_columns}\")\n",
        "    return X_new, selected_columns\n",
        "\n",
        "X_new, selected_columns = chi_square_selection(X, y_discretized, k=10)\n",
        "\n",
        "# Train-test split with selected features\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y_discretized, test_size=0.1, random_state=4)\n",
        "\n",
        "def evaluate_model(y_test, y_pred):\n",
        "    print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "    print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "    print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "    print(\"R2 Score: %.2f\" % r2_score(y_test, y_pred))\n",
        "    print(\"MAPE Score: %.2f\" % (np.mean(np.abs((y_test - y_pred) / np.clip(y_test, 1e-8, np.inf))) * 100))\n",
        "\n",
        "# Linear Regression\n",
        "print(\"\\nOLS Linear Regression\")\n",
        "model = sm.OLS(endog=y_train, exog=X_train).fit()\n",
        "y_pred = model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred)\n",
        "\n",
        "print(\"\\nMultivariable Linear Regression\")\n",
        "regression = LinearRegression()\n",
        "model = regression.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred)\n",
        "\n",
        "# Decision Tree Regression\n",
        "print(\"\\nDecision Tree Regression\")\n",
        "regressor = DecisionTreeRegressor(random_state=0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred)\n",
        "\n",
        "# Polynomial Regression\n",
        "print(\"\\nPolynomial Regression\")\n",
        "poly_reg = PolynomialFeatures(degree=4)\n",
        "X_poly = poly_reg.fit_transform(X_train)\n",
        "regressor = LinearRegression()\n",
        "model = regressor.fit(X_poly, y_train)\n",
        "y_pred = model.predict(poly_reg.transform(X_test))\n",
        "evaluate_model(y_test, y_pred)\n",
        "\n",
        "# Random Forest Regression\n",
        "print(\"\\nRandom Forest Regression\")\n",
        "regressor = RandomForestRegressor(n_estimators=10, random_state=0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b8bS3uxQu7e",
        "outputId": "1d377331-4d0e-412c-ea31-6b95afe4b64c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features after Chi-Square test: Index(['Kindly mention your age?', 'Your matric marks percentage?',\n",
            "       'Your Fsc/Ics marks percentage?', 'Please mention your NTS score?',\n",
            "       'How much you have interest in this domain',\n",
            "       'Are you satisfied with your program selection?',\n",
            "       'Please provide your current CGPA?',\n",
            "       'Do you find your CS/SE subjects difficult?',\n",
            "       'Do you love your subjects?', 'Kindly specify do you love travelling?'],\n",
            "      dtype='object')\n",
            "\n",
            "OLS Linear Regression\n",
            "MAE Score:  0.30755634101911494\n",
            "MSE Score:  0.14801551206184052\n",
            "RMSE Score:  0.3847278415475549\n",
            "R2 Score: 0.80\n",
            "MAPE Score: 47984512.98\n",
            "\n",
            "Multivariable Linear Regression\n",
            "MAE Score:  0.3181687270241447\n",
            "MSE Score:  0.15821095748419747\n",
            "RMSE Score:  0.3977574103447948\n",
            "R2 Score: 0.79\n",
            "MAPE Score: 36753764.21\n",
            "\n",
            "Decision Tree Regression\n",
            "MAE Score:  0.27586206896551724\n",
            "MSE Score:  0.3103448275862069\n",
            "RMSE Score:  0.5570860145311556\n",
            "R2 Score: 0.58\n",
            "MAPE Score: 172413801.72\n",
            "\n",
            "Polynomial Regression\n",
            "MAE Score:  2.2191846197519722\n",
            "MSE Score:  9.798427285700884\n",
            "RMSE Score:  3.130243965843698\n",
            "R2 Score: -12.18\n",
            "MAPE Score: 1308313509.51\n",
            "\n",
            "Random Forest Regression\n",
            "MAE Score:  0.27068965517241383\n",
            "MSE Score:  0.16431034482758622\n",
            "RMSE Score:  0.4053521244888032\n",
            "R2 Score: 0.78\n",
            "MAPE Score: 189655183.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **With VIF**"
      ],
      "metadata": {
        "id": "LfS3MD_WVN3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import StandardScaler  # Z-score Normalization\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('students_responses_main.csv')\n",
        "df_org = df.copy()\n",
        "df.head()\n",
        "\n",
        "# Data cleaning steps\n",
        "df.drop(columns=df.columns[88], inplace=True)\n",
        "df.drop(columns=df.columns[74], inplace=True)\n",
        "df.drop(columns=df.columns[58], inplace=True)\n",
        "df.drop(columns=df.columns[12:50], inplace=True)\n",
        "df.drop(columns=df.columns[10], inplace=True)\n",
        "df.drop(columns=df.columns[8], inplace=True)\n",
        "df.drop(columns=df.columns[7], inplace=True)\n",
        "df.drop(columns=df.columns[0], inplace=True)\n",
        "\n",
        "# Modify the semester column\n",
        "df['Kindly choose your current semester.'] = (\n",
        "    df['Kindly choose your current semester.']\n",
        "    .str.replace('2 Semester', '1 Semester', regex=True)\n",
        "    .str.replace('3 Semester', '2 Semester', regex=True)\n",
        "    .str.replace('4 Semester', '3 Semester', regex=True)\n",
        "    .str.replace('5 Semester', '4 Semester', regex=True)\n",
        "    .str.replace('6 Semester', '5 Semester', regex=True)\n",
        "    .str.replace('7 Semester', '6 Semester', regex=True)\n",
        "    .str.replace('8 Semester', '7 Semester', regex=True)\n",
        ")\n",
        "\n",
        "# Fix the matric and Fsc/Ics marks\n",
        "df['Your matric marks percentage?'] = np.where(\n",
        "    df['Your matric marks percentage?'] > 100,\n",
        "    df['Your matric marks percentage?'] * 100 / 1100,\n",
        "    df['Your matric marks percentage?']\n",
        ")\n",
        "\n",
        "df[\"Your Fsc/Ics marks percentage?\"] = np.where(\n",
        "    df[\"Your Fsc/Ics marks percentage?\"] > 100,\n",
        "    df[\"Your Fsc/Ics marks percentage?\"] * 100 / 1100,\n",
        "    df[\"Your Fsc/Ics marks percentage?\"]\n",
        ")\n",
        "\n",
        "df.round(decimals=2)\n",
        "\n",
        "# Handle outliers using IQR method\n",
        "df = df.select_dtypes(include=['number'])\n",
        "Q1 = df.quantile(0.15)\n",
        "Q3 = df.quantile(0.85)\n",
        "IQR = Q3 - Q1\n",
        "df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# Factorize categorical columns\n",
        "def factorize_fun(data):\n",
        "    obj_cols = data.loc[:, data.dtypes == object].columns\n",
        "    for col in obj_cols:\n",
        "        data[col] = pd.factorize(data[col])[0] + 1\n",
        "    return data\n",
        "\n",
        "df = factorize_fun(df)\n",
        "\n",
        "# Impute missing values using KNN\n",
        "def knn_null(df):\n",
        "    imputer = KNNImputer(n_neighbors=2)\n",
        "    df1 = imputer.fit_transform(df)\n",
        "    df2 = pd.DataFrame(df1, columns=df.columns)\n",
        "    return df2\n",
        "\n",
        "df = knn_null(df)\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = df.drop(columns=['Please mention your Previous Semester GPA?'])\n",
        "y = df['Please mention your Previous Semester GPA?']\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred, clip_threshold=1.0):\n",
        "    # Clip the values in y_true to avoid division by very small numbers (close to 0)\n",
        "    y_true_clipped = np.clip(y_true, clip_threshold, np.inf)  # Clip values below `clip_threshold`\n",
        "    return np.mean(np.abs((y_true_clipped - y_pred) / y_true_clipped)) * 100\n",
        "\n",
        "# Z-Score Normalization\n",
        "def zscore_normalize(df):\n",
        "    scaler = StandardScaler()  # Using StandardScaler for Z-score\n",
        "    data_scaled = scaler.fit_transform(df)\n",
        "    return pd.DataFrame(data_scaled, columns=df.columns)  # Return DataFrame to retain column names\n",
        "\n",
        "X = zscore_normalize(X)\n",
        "\n",
        "# Calculate VIF function\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def calculate_vif(X):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Feature\"] = X.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "# Calculate VIF before training\n",
        "vif_data = calculate_vif(X)\n",
        "print(\"VIF values:\\n\", vif_data)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=4)\n",
        "\n",
        "print(\"OLS Linear Regression\")\n",
        "model = sm.OLS(endog=y_train, exog=X_train).fit()\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test, y_pred))\n",
        "\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "print(\"Multivariable Linear Regression\")\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "regression = LinearRegression()\n",
        "model = regression.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test, y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "print(\"Decision Tree\")\n",
        "regressor = DecisionTreeRegressor(random_state=0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test, y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "print(\"Polynomial Regression\")\n",
        "poly_reg = PolynomialFeatures(degree=4)\n",
        "X_poly = poly_reg.fit_transform(X_train)\n",
        "regressor = LinearRegression()\n",
        "model = regressor.fit(X_poly, y_train)\n",
        "y_pred = model.predict(poly_reg.transform(X_test))\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test, y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "print(\"RandomForestRegressor\")\n",
        "regressor = RandomForestRegressor(n_estimators=10, random_state=0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test, y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkY9pdqlTTDo",
        "outputId": "4eac29fd-2afc-419e-f894-51549261513b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VIF values:\n",
            "                                            Feature       VIF\n",
            "0                         Kindly mention your age?  1.226576\n",
            "1             How many members are in your family?  1.048057\n",
            "2                    Your matric marks percentage?  1.319144\n",
            "3                   Your Fsc/Ics marks percentage?  1.444562\n",
            "4                   Please mention your NTS score?  1.054354\n",
            "5        How much you have interest in this domain  2.220499\n",
            "6   Are you satisfied with your program selection?  2.395394\n",
            "7                Please provide your current CGPA?  1.294690\n",
            "8       Do you find your CS/SE subjects difficult?  1.277991\n",
            "9                       Do you love your subjects?  1.764862\n",
            "10                              How is your health  1.140766\n",
            "11            Do you like your teacher methodology  1.123784\n",
            "12          Kindly specify do you love travelling?  1.039357\n",
            "13                      Do you love reading books?  1.061514\n",
            "OLS Linear Regression\n",
            "MAE Score:  2.938693946115207\n",
            "MSE Score:  8.727283095416277\n",
            "RMSE Score:  2.954197538320056\n",
            "R2 score : -22.14\n",
            "MAPE Score: 111.24\n",
            "Multivariable Linear Regression\n",
            "MAE Score:  0.12965921277227507\n",
            "MSE Score:  0.03385971687400962\n",
            "RMSE Score:  0.18401009992391618\n",
            "R2 score : 0.91\n",
            "MAPE Score: 5.15\n",
            "Decision Tree\n",
            "MAE Score:  0.2256034482758621\n",
            "MSE Score:  0.13567246551724138\n",
            "RMSE Score:  0.36833743431430016\n",
            "R2 score : 0.64\n",
            "MAPE Score: 9.68\n",
            "Polynomial Regression\n",
            "MAE Score:  0.6574515034251454\n",
            "MSE Score:  2.0801878299337857\n",
            "RMSE Score:  1.4422856270287747\n",
            "R2 score : -4.52\n",
            "MAPE Score: 31.71\n",
            "RandomForestRegressor\n",
            "MAE Score:  0.1401637931034483\n",
            "MSE Score:  0.03517093637931034\n",
            "RMSE Score:  0.1875391595888985\n",
            "R2 score : 0.91\n",
            "MAPE Score: 5.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **With PCC**"
      ],
      "metadata": {
        "id": "Y89GZOOfVvkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import statsmodels.api as sm\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/students_responses_main.csv')\n",
        "df_org = df.copy()\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(columns= df.columns[88], inplace=True)\n",
        "df.drop(columns= df.columns[74], inplace=True)\n",
        "df.drop(columns= df.columns[58], inplace=True)\n",
        "df.drop(columns = df.columns[12:50], inplace = True)\n",
        "df.drop(columns= df.columns[10], inplace=True)\n",
        "df.drop(columns= df.columns[8], inplace=True)\n",
        "df.drop(columns= df.columns[7], inplace=True)\n",
        "df.drop(columns= df.columns[0], inplace=True)\n",
        "\n",
        "# Data cleaning\n",
        "df['Kindly choose your current semester.'] = df['Kindly choose your current semester.'].str.replace('2 Semester','1 Semester',regex=True).str.replace('3 Semester','2 Semester',regex=True).str.replace('4 Semester','3 Semester',regex=True).str.replace('5 Semester','4 Semester',regex=True).str.replace('6 Semester','5 Semester',regex=True).str.replace('7 Semester','6 Semester',regex=True).str.replace('8 Semester','7 Semester',regex=True)\n",
        "\n",
        "df['Your matric marks percentage?'] = np.where(df['Your matric marks percentage?'] > 100,\n",
        "                                               df['Your matric marks percentage?'] * 100 / 1100,\n",
        "                                               df['Your matric marks percentage?'])\n",
        "\n",
        "df[\"Your Fsc/Ics marks percentage?\"] = np.where(df[\"Your Fsc/Ics marks percentage?\"] > 100,\n",
        "                                                df[\"Your Fsc/Ics marks percentage?\"]* 100/1100,\n",
        "                                                df[\"Your Fsc/Ics marks percentage?\"])\n",
        "\n",
        "df.round(decimals=2)\n",
        "\n",
        "# Remove outliers based on IQR\n",
        "df = df.select_dtypes(include=['number'])\n",
        "Q1 = df.quantile(0.15)\n",
        "Q3 = df.quantile(0.85)\n",
        "IQR = Q3 - Q1\n",
        "df = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "df.describe()\n",
        "\n",
        "# Function to factorize object columns\n",
        "def factorize_fun(data):\n",
        "    obj_cols = data.loc[:, data.dtypes == object].columns\n",
        "    for col in obj_cols:\n",
        "        data[col] = pd.factorize(data[col])[0] + 1\n",
        "    return data\n",
        "\n",
        "df = factorize_fun(df)\n",
        "\n",
        "# Handle missing data using KNN Imputation\n",
        "def knn_null(df):\n",
        "    imputer = KNNImputer(n_neighbors=2)\n",
        "    df1 = imputer.fit_transform(df)\n",
        "    df2 = pd.DataFrame(df1, columns = df.columns)\n",
        "    return df2\n",
        "\n",
        "df = knn_null(df)\n",
        "\n",
        "# Normalize the data\n",
        "def normalize(df):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(df)\n",
        "    return data_scaled\n",
        "\n",
        "# Apply Z-score Transformation to the features\n",
        "scaler = StandardScaler()\n",
        "df_scaled = df.copy()\n",
        "df_scaled[df_scaled.select_dtypes(include=['number']).columns] = scaler.fit_transform(df_scaled.select_dtypes(include=['number']))\n",
        "\n",
        "# Correlation matrix\n",
        "correlation_matrix = df_scaled.corr()\n",
        "\n",
        "# Split the data\n",
        "X = df_scaled.drop(columns=['Please mention your Previous Semester GPA?'])\n",
        "y = df_scaled['Please mention your Previous Semester GPA?']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=4)\n",
        "\n",
        "# Define function to calculate PCC\n",
        "def pearson_correlation_coefficient(y_true, y_pred):\n",
        "    return np.corrcoef(y_true, y_pred)[0, 1]\n",
        "\n",
        "# Define function to calculate MAPE\n",
        "def mean_absolute_percentage_error(y_true, y_pred, clip_threshold=1.0):\n",
        "    y_true_clipped = np.clip(y_true, clip_threshold, np.inf)\n",
        "    return np.mean(np.abs((y_true_clipped - y_pred) / y_true_clipped)) * 100\n",
        "\n",
        "# Linear Regression using statsmodels (OLS)\n",
        "print(\"OLS Linear Regression\")\n",
        "model = sm.OLS(endog=y_train, exog=X_train).fit()\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Linear Regression using sklearn\n",
        "print(\"Multivariable Linear Regression\")\n",
        "regression = LinearRegression()\n",
        "model = regression.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Decision Tree Regression\n",
        "print(\"Decision Tree\")\n",
        "regressor = DecisionTreeRegressor(random_state=0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Polynomial Regression\n",
        "print(\"Polynomial Regression\")\n",
        "poly_reg = PolynomialFeatures(degree=4)\n",
        "X_poly = poly_reg.fit_transform(X_train)\n",
        "regressor = LinearRegression()\n",
        "model = regressor.fit(X_poly, y_train)\n",
        "y_pred = model.predict(poly_reg.transform(X_test))\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Random Forest Regressor\n",
        "print(\"Random Forest Regressor\")\n",
        "regressor = RandomForestRegressor(n_estimators=10, random_state=0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4EqXXP-UuG5",
        "outputId": "e03d2008-1be8-4471-e9e4-1dedecd3560d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OLS Linear Regression\n",
            "MAE Score:  0.23937717188296959\n",
            "MSE Score:  0.11545728939159992\n",
            "RMSE Score:  0.33979006664645145\n",
            "R2 score : 0.91\n",
            "MAPE Score: 115.36\n",
            "Multivariable Linear Regression\n",
            "MAE Score:  0.23945235288153546\n",
            "MSE Score:  0.11548212826645306\n",
            "RMSE Score:  0.3398266150060249\n",
            "R2 score : 0.91\n",
            "MAPE Score: 115.44\n",
            "Decision Tree\n",
            "MAE Score:  0.4348854154605512\n",
            "MSE Score:  0.4620155237937227\n",
            "RMSE Score:  0.6797172381172355\n",
            "R2 score : 0.64\n",
            "MAPE Score: 122.92\n",
            "Polynomial Regression\n",
            "MAE Score:  1.2141004074256523\n",
            "MSE Score:  7.095298276031791\n",
            "RMSE Score:  2.663700110003337\n",
            "R2 score : -4.52\n",
            "MAPE Score: 200.97\n",
            "Random Forest Regressor\n",
            "MAE Score:  0.24868198735455052\n",
            "MSE Score:  0.1113195769524924\n",
            "RMSE Score:  0.3336458855620617\n",
            "R2 score : 0.91\n",
            "MAPE Score: 115.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NNYoxn70VucM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}