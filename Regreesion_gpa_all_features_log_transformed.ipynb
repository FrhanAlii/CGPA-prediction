{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **With Variance infaltion factor**"
      ],
      "metadata": {
        "id": "OqVNPbyoKxpp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrJ1DfXLKew6",
        "outputId": "d56a60c0-8fd9-45e4-bffe-11e1b8996688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-e0cc16745bb4>:73: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df_log = df_log.applymap(lambda x: np.log(x) if x > 0 else 0)  # Apply log transform only to positive values\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VIF values:\n",
            "                                            Feature        VIF\n",
            "0                         Kindly mention your age?   7.550438\n",
            "1             How many members are in your family?  17.566814\n",
            "2                    Your matric marks percentage?  29.770506\n",
            "3                   Your Fsc/Ics marks percentage?  26.783510\n",
            "4                   Please mention your NTS score?  25.717172\n",
            "5        How much you have interest in this domain  33.557429\n",
            "6   Are you satisfied with your program selection?  26.264332\n",
            "7                Please provide your current CGPA?  33.243398\n",
            "8       Do you find your CS/SE subjects difficult?  11.234943\n",
            "9                       Do you love your subjects?  15.661183\n",
            "10                              How is your health  15.219516\n",
            "11            Do you like your teacher methodology   8.187363\n",
            "12          Kindly specify do you love travelling?  11.065933\n",
            "13                      Do you love reading books?   4.472995\n",
            "ols linear Regression\n",
            "MAE Score:  0.04964231008953195\n",
            "MSE Score:  0.005786342471389313\n",
            "RMSE Score:  0.07606801214301129\n",
            "R2 score : 0.91\n",
            "MAPE Score: 0.07\n",
            "multivariable linear Regression\n",
            "MAE Score:  0.0512588880595669\n",
            "MSE Score:  0.005969732937997926\n",
            "RMSE Score:  0.07726404686526539\n",
            "R2 score : 0.91\n",
            "MAPE Score: 0.07\n",
            "Decission Tree\n",
            "MAE Score:  0.09475187137475762\n",
            "MSE Score:  0.03470431945169244\n",
            "RMSE Score:  0.18629095375699925\n",
            "R2 score : 0.45\n",
            "MAPE Score: 0.21\n",
            "Polynomial Regression\n",
            "MAE Score:  0.30923955239510514\n",
            "MSE Score:  0.23101007209742708\n",
            "RMSE Score:  0.4806350716473228\n",
            "R2 score : -2.66\n",
            "MAPE Score: 0.44\n",
            "RandomForestRegressor\n",
            "MAE Score:  0.059493742512230184\n",
            "MSE Score:  0.007951834204981406\n",
            "RMSE Score:  0.08917305761821452\n",
            "R2 score : 0.87\n",
            "MAPE Score: 0.08\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Load dataset\n",
        "df  = pd.read_csv('students_responses_main.csv')\n",
        "df_org = df.copy()\n",
        "df.head()\n",
        "\n",
        "# Data cleaning steps (same as original)\n",
        "df.drop(columns= df.columns[88], inplace=True)\n",
        "df.drop(columns= df.columns[74], inplace=True)\n",
        "df.drop(columns= df.columns[58], inplace=True)\n",
        "df.drop(columns = df.columns[12:50], inplace=True)\n",
        "df.drop(columns= df.columns[10], inplace=True)\n",
        "df.drop(columns= df.columns[8], inplace=True)\n",
        "df.drop(columns= df.columns[7], inplace=True)\n",
        "df.drop(columns= df.columns[0], inplace=True)\n",
        "\n",
        "# Modify the semester column\n",
        "df['Kindly choose your current semester.'] = df['Kindly choose your current semester.'].str.replace('2 Semester','1 Semester',regex=True).str.replace('3 Semester','2 Semester',regex=True).str.replace ('4 Semester','3 Semester',regex=True).str.replace ('5 Semester','4 Semester',regex=True).str.replace ('6 Semester','5 Semester',regex=True).str.replace('7 Semester','6 Semester',regex=True).str.replace('8 Semester','7 Semester',regex=True)\n",
        "\n",
        "# Fix the matric and Fsc/Ics marks (same as original)\n",
        "df['Your matric marks percentage?'] = np.where(df['Your matric marks percentage?'] > 100,\n",
        "                                               df['Your matric marks percentage?'] * 100 / 1100,\n",
        "                                               df['Your matric marks percentage?'])\n",
        "\n",
        "df[\"Your Fsc/Ics marks percentage?\"] = np.where(df[\"Your Fsc/Ics marks percentage?\"] > 100,\n",
        "                                                df[\"Your Fsc/Ics marks percentage?\"]* 100/1100,\n",
        "                                                df[\"Your Fsc/Ics marks percentage?\"])\n",
        "\n",
        "df.round(decimals=2)\n",
        "\n",
        "# Handle outliers using IQR method (same as original)\n",
        "df = df.select_dtypes(include=['number'])\n",
        "Q1 = df.quantile(0.15)\n",
        "Q3 = df.quantile(0.85)\n",
        "IQR = Q3 - Q1\n",
        "df = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# Factorize categorical columns (same as original)\n",
        "def factorize_fun(data):\n",
        "    obj_cols = data.loc[:, data.dtypes == object].columns\n",
        "    for col in obj_cols:\n",
        "        data[col] = pd.factorize(data[col])[0] +1\n",
        "    return data\n",
        "\n",
        "df = factorize_fun(df)\n",
        "\n",
        "# Impute missing values using KNN (same as original)\n",
        "def knn_null(df):\n",
        "    imputer = KNNImputer(n_neighbors=2)\n",
        "    df1 = imputer.fit_transform(df)\n",
        "    df2 = pd.DataFrame(df1, columns = df.columns)\n",
        "    return df2\n",
        "\n",
        "df = knn_null(df)\n",
        "\n",
        "# Log-transform the features and the target\n",
        "df_log = df.copy()\n",
        "df_log = df_log.applymap(lambda x: np.log(x) if x > 0 else 0)  # Apply log transform only to positive values\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = df_log.drop(columns=['Please mention your Previous Semester GPA?'])\n",
        "y = df_log['Please mention your Previous Semester GPA?']\n",
        "\n",
        "# Normalize the features\n",
        "def normalize(df):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(df)\n",
        "    return pd.DataFrame(data_scaled, columns=df.columns)  # Return DataFrame to retain column names\n",
        "\n",
        "X = normalize(X)\n",
        "\n",
        "# Calculate VIF function (same as original)\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def calculate_vif(X):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Feature\"] = X.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "# Calculate VIF before training\n",
        "vif_data = calculate_vif(X)\n",
        "print(\"VIF values:\\n\", vif_data)\n",
        "\n",
        "# Train-test split (same as original)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=4)\n",
        "\n",
        "# OLS Linear Regression\n",
        "print(\"ols linear Regression\")\n",
        "model = sm.OLS(endog=y_train, exog=X_train).fit()\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Multivariable Linear Regression\n",
        "print(\"multivariable linear Regression\")\n",
        "regression = LinearRegression()\n",
        "model = regression.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Decision Tree\n",
        "print(\"Decission Tree\")\n",
        "regressor = DecisionTreeRegressor(random_state = 0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Polynomial Regression\n",
        "print(\"Polynomial Regression\")\n",
        "poly_reg = PolynomialFeatures(degree = 4)\n",
        "X_poly = poly_reg.fit_transform(X_train)\n",
        "regressor = LinearRegression()\n",
        "model = regressor.fit(X_poly, y_train)\n",
        "y_pred = model.predict(poly_reg.transform(X_test))\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# RandomForestRegressor\n",
        "print(\"RandomForestRegressor\")\n",
        "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **with Mutual Information**"
      ],
      "metadata": {
        "id": "eIQu_cs2Lyyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('students_responses_main.csv')\n",
        "df_org = df.copy()\n",
        "df.head()\n",
        "\n",
        "# Data cleaning steps\n",
        "df.drop(columns= df.columns[88], inplace=True)\n",
        "df.drop(columns= df.columns[74], inplace=True)\n",
        "df.drop(columns= df.columns[58], inplace=True)\n",
        "df.drop(columns = df.columns[12:50], inplace=True)\n",
        "df.drop(columns= df.columns[10], inplace=True)\n",
        "df.drop(columns= df.columns[8], inplace=True)\n",
        "df.drop(columns= df.columns[7], inplace=True)\n",
        "df.drop(columns= df.columns[0], inplace=True)\n",
        "\n",
        "# Modify the semester column\n",
        "df['Kindly choose your current semester.'] = df['Kindly choose your current semester.'].str.replace('2 Semester','1 Semester',regex=True).str.replace('3 Semester','2 Semester',regex=True).str.replace ('4 Semester','3 Semester',regex=True).str.replace ('5 Semester','4 Semester',regex=True).str.replace ('6 Semester','5 Semester',regex=True).str.replace('7 Semester','6 Semester',regex=True).str.replace('8 Semester','7 Semester',regex=True)\n",
        "\n",
        "# Fix the matric and Fsc/Ics marks with log transformation\n",
        "df['Your matric marks percentage?'] = np.where(df['Your matric marks percentage?'] > 100,\n",
        "                                               df['Your matric marks percentage?'] * 100 / 1100,\n",
        "                                               df['Your matric marks percentage?'])\n",
        "df[\"Your Fsc/Ics marks percentage?\"] = np.where(df[\"Your Fsc/Ics marks percentage?\"] > 100,\n",
        "                                                df[\"Your Fsc/Ics marks percentage?\"] * 100 / 1100,\n",
        "                                                df[\"Your Fsc/Ics marks percentage?\"])\n",
        "\n",
        "# Apply log transformation to these columns\n",
        "df['Your matric marks percentage?'] = df['Your matric marks percentage?'].apply(lambda x: np.log(x + 1) if x > 0 else 0)\n",
        "df[\"Your Fsc/Ics marks percentage?\"] = df[\"Your Fsc/Ics marks percentage?\"].apply(lambda x: np.log(x + 1) if x > 0 else 0)\n",
        "\n",
        "df.round(decimals=2)\n",
        "\n",
        "# Handle outliers using IQR method\n",
        "df = df.select_dtypes(include=['number'])\n",
        "Q1 = df.quantile(0.15)\n",
        "Q3 = df.quantile(0.85)\n",
        "IQR = Q3 - Q1\n",
        "df = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# Factorize categorical columns\n",
        "def factorize_fun(data):\n",
        "    obj_cols = data.loc[:, data.dtypes == object].columns\n",
        "    for col in obj_cols:\n",
        "        data[col] = pd.factorize(data[col])[0] + 1\n",
        "    return data\n",
        "\n",
        "df = factorize_fun(df)\n",
        "\n",
        "# Impute missing values using KNN\n",
        "def knn_null(df):\n",
        "    imputer = KNNImputer(n_neighbors=2)\n",
        "    df1 = imputer.fit_transform(df)\n",
        "    df2 = pd.DataFrame(df1, columns = df.columns)\n",
        "    return df2\n",
        "\n",
        "df = knn_null(df)\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = df.drop(columns=['Please mention your Previous Semester GPA?'])\n",
        "y = df['Please mention your Previous Semester GPA?']\n",
        "\n",
        "# Normalize the features\n",
        "def normalize(df):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(df)\n",
        "    return pd.DataFrame(data_scaled, columns=df.columns)  # Return DataFrame to retain column names\n",
        "\n",
        "X = normalize(X)\n",
        "\n",
        "# Mutual Information for Feature Selection (regression)\n",
        "def mutual_info_selection(X, y, k=10):\n",
        "    # Select top k features based on mutual information for regression\n",
        "    mi_selector = SelectKBest(mutual_info_regression, k=k)\n",
        "    X_new = mi_selector.fit_transform(X, y)\n",
        "    selected_columns = X.columns[mi_selector.get_support()]\n",
        "    print(f\"Selected features after Mutual Information test: {selected_columns}\")\n",
        "    return X_new, selected_columns\n",
        "\n",
        "X_new, selected_columns = mutual_info_selection(X, y, k=10)\n",
        "\n",
        "# Train-test split with selected features\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.1, random_state=4)\n",
        "\n",
        "# Linear Regression Model\n",
        "print(\"OLS Linear Regression\")\n",
        "model = sm.OLS(endog=y_train, exog=X_train).fit()\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test, y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Multivariable Linear Regression using Sklearn\n",
        "print(\"Multivariable Linear Regression\")\n",
        "regression = LinearRegression()\n",
        "model = regression.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test, y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Decision Tree Regressor\n",
        "print(\"Decision Tree\")\n",
        "regressor = DecisionTreeRegressor(random_state=0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test, y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Polynomial Regression\n",
        "print(\"Polynomial Regression\")\n",
        "poly_reg = PolynomialFeatures(degree=4)\n",
        "X_poly = poly_reg.fit_transform(X_train)\n",
        "regressor = LinearRegression()\n",
        "model = regressor.fit(X_poly, y_train)\n",
        "y_pred = model.predict(poly_reg.transform(X_test))\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test, y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# RandomForestRegressor\n",
        "print(\"Random Forest Regressor\")\n",
        "regressor = RandomForestRegressor(n_estimators=10, random_state=0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test, y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLuvxaz3KmFS",
        "outputId": "3fac3613-5229-44bf-9083-89494a843742"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features after Mutual Information test: Index(['Kindly mention your age?', 'How many members are in your family?',\n",
            "       'Your matric marks percentage?', 'Your Fsc/Ics marks percentage?',\n",
            "       'Please mention your NTS score?',\n",
            "       'Are you satisfied with your program selection?',\n",
            "       'Please provide your current CGPA?',\n",
            "       'Do you find your CS/SE subjects difficult?',\n",
            "       'Do you love your subjects?', 'Do you love reading books?'],\n",
            "      dtype='object')\n",
            "OLS Linear Regression\n",
            "MAE Score:  0.25450171730785004\n",
            "MSE Score:  0.19191155364123239\n",
            "RMSE Score:  0.4380771092413211\n",
            "R2 score : 0.57\n",
            "MAPE Score: 0.13\n",
            "Multivariable Linear Regression\n",
            "MAE Score:  0.2166478101628042\n",
            "MSE Score:  0.17534270200162239\n",
            "RMSE Score:  0.41873942016679344\n",
            "R2 score : 0.61\n",
            "MAPE Score: 0.11\n",
            "Decision Tree\n",
            "MAE Score:  0.2619824561403508\n",
            "MSE Score:  0.20864577192982456\n",
            "RMSE Score:  0.4567775956960067\n",
            "R2 score : 0.53\n",
            "MAPE Score: 0.13\n",
            "Polynomial Regression\n",
            "MAE Score:  1.70571654976469\n",
            "MSE Score:  7.671980939303921\n",
            "RMSE Score:  2.7698340995994544\n",
            "R2 score : -16.10\n",
            "MAPE Score: 0.71\n",
            "Random Forest Regressor\n",
            "MAE Score:  0.26251929824561404\n",
            "MSE Score:  0.2067911\n",
            "RMSE Score:  0.454742894391985\n",
            "R2 score : 0.54\n",
            "MAPE Score: 0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CHI-square**"
      ],
      "metadata": {
        "id": "iqlU3EN0MMgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.preprocessing import LabelEncoder, KBinsDiscretizer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('students_responses_main.csv')\n",
        "df_org = df.copy()\n",
        "\n",
        "# Data cleaning steps\n",
        "df.drop(columns= df.columns[88], inplace=True)\n",
        "df.drop(columns= df.columns[74], inplace=True)\n",
        "df.drop(columns= df.columns[58], inplace=True)\n",
        "df.drop(columns = df.columns[12:50], inplace=True)\n",
        "df.drop(columns= df.columns[10], inplace=True)\n",
        "df.drop(columns= df.columns[8], inplace=True)\n",
        "df.drop(columns= df.columns[7], inplace=True)\n",
        "df.drop(columns= df.columns[0], inplace=True)\n",
        "\n",
        "# Modify the semester column\n",
        "df['Kindly choose your current semester.'] = df['Kindly choose your current semester.'].str.replace('2 Semester','1 Semester',regex=True).str.replace('3 Semester','2 Semester',regex=True).str.replace ('4 Semester','3 Semester',regex=True).str.replace ('5 Semester','4 Semester',regex=True).str.replace ('6 Semester','5 Semester',regex=True).str.replace('7 Semester','6 Semester',regex=True).str.replace('8 Semester','7 Semester',regex=True)\n",
        "\n",
        "# Fix the matric and Fsc/Ics marks\n",
        "df['Your matric marks percentage?'] = np.where(df['Your matric marks percentage?'] > 100,\n",
        "                                               df['Your matric marks percentage?'] * 100 / 1100,\n",
        "                                               df['Your matric marks percentage?'])\n",
        "\n",
        "df[\"Your Fsc/Ics marks percentage?\"] = np.where(df[\"Your Fsc/Ics marks percentage?\"] > 100,\n",
        "                                                df[\"Your Fsc/Ics marks percentage?\"]* 100/1100,\n",
        "                                                df[\"Your Fsc/Ics marks percentage?\"])\n",
        "\n",
        "df.round(decimals=2)\n",
        "\n",
        "# Handle outliers using IQR method\n",
        "df = df.select_dtypes(include=['number'])\n",
        "Q1 = df.quantile(0.15)\n",
        "Q3 = df.quantile(0.85)\n",
        "IQR = Q3 - Q1\n",
        "df = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# Factorize categorical columns\n",
        "def factorize_fun(data):\n",
        "    obj_cols = data.loc[:, data.dtypes == object].columns\n",
        "    for col in obj_cols:\n",
        "        data[col] = pd.factorize(data[col])[0] +1\n",
        "    return data\n",
        "\n",
        "df = factorize_fun(df)\n",
        "\n",
        "# Impute missing values using KNN\n",
        "def knn_null(df):\n",
        "    imputer = KNNImputer(n_neighbors=2)\n",
        "    df1 = imputer.fit_transform(df)\n",
        "    df2 = pd.DataFrame(df1, columns = df.columns)\n",
        "    return df2\n",
        "\n",
        "df = knn_null(df)\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = df.drop(columns=['Please mention your Previous Semester GPA?'])\n",
        "y = df['Please mention your Previous Semester GPA?']\n",
        "\n",
        "# Apply log transformation to features\n",
        "def log_transform(df):\n",
        "    return np.log1p(df)\n",
        "\n",
        "X_log = log_transform(X)\n",
        "\n",
        "# Modified MAPE calculation to handle small values in the denominator\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    # Adding a small epsilon value to the denominator to prevent division by zero\n",
        "    epsilon = 1e-10\n",
        "    return np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100\n",
        "\n",
        "# Use this modified version of MAPE in your code where needed\n",
        "# print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Normalize the features\n",
        "def normalize(df):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(df)\n",
        "    return pd.DataFrame(data_scaled, columns=df.columns)  # Return DataFrame to retain column names\n",
        "\n",
        "X_log = normalize(X_log)\n",
        "\n",
        "# Discretize the target variable to make it categorical\n",
        "def discretize_target(y, n_bins=5):\n",
        "    discretizer = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
        "    y_discretized = discretizer.fit_transform(y.values.reshape(-1, 1))\n",
        "    return y_discretized.flatten()  # Flatten the array to avoid shape issues\n",
        "\n",
        "y_discretized = discretize_target(y)\n",
        "\n",
        "# Chi-Square feature selection\n",
        "def chi_square_selection(X, y, k=10):\n",
        "    chi2_selector = SelectKBest(chi2, k=k)\n",
        "    X_new = chi2_selector.fit_transform(X, y)\n",
        "    selected_columns = X.columns[chi2_selector.get_support()]\n",
        "    print(f\"Selected features after Chi-Square test: {selected_columns}\")\n",
        "    return X_new, selected_columns\n",
        "\n",
        "X_new, selected_columns = chi_square_selection(X_log, y_discretized, k=10)\n",
        "\n",
        "# Train-test split with selected features\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y_discretized, test_size=0.1, random_state=4)\n",
        "\n",
        "# Linear Regression using statsmodels (OLS)\n",
        "print(\"OLS Linear Regression\")\n",
        "model = sm.OLS(endog=y_train, exog=X_train).fit()\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Linear Regression using sklearn\n",
        "print(\"Multivariable Linear Regression\")\n",
        "regression = LinearRegression()\n",
        "model = regression.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Decision Tree Regression\n",
        "print(\"Decision Tree\")\n",
        "regressor = DecisionTreeRegressor(random_state=0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Polynomial Regression\n",
        "print(\"Polynomial Regression\")\n",
        "poly_reg = PolynomialFeatures(degree=4)\n",
        "X_poly = poly_reg.fit_transform(X_train)\n",
        "regressor = LinearRegression()\n",
        "model = regressor.fit(X_poly, y_train)\n",
        "y_pred = model.predict(poly_reg.transform(X_test))\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Random Forest Regressor\n",
        "print(\"Random Forest Regressor\")\n",
        "regressor = RandomForestRegressor(n_estimators=10, random_state=0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y1LIW3bLxYx",
        "outputId": "2163bb31-ddf4-485e-c259-a750aa14052d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features after Chi-Square test: Index(['Kindly mention your age?', 'Your Fsc/Ics marks percentage?',\n",
            "       'Please mention your NTS score?',\n",
            "       'How much you have interest in this domain',\n",
            "       'Are you satisfied with your program selection?',\n",
            "       'Please provide your current CGPA?',\n",
            "       'Do you find your CS/SE subjects difficult?',\n",
            "       'Do you love your subjects?', 'Kindly specify do you love travelling?',\n",
            "       'Do you love reading books?'],\n",
            "      dtype='object')\n",
            "OLS Linear Regression\n",
            "MAE Score:  0.2935206848407386\n",
            "MSE Score:  0.1418303995426236\n",
            "RMSE Score:  0.3766037699527497\n",
            "R2 score : 0.81\n",
            "MAPE Score: 3346783332.77\n",
            "Multivariable Linear Regression\n",
            "MAE Score:  0.31316518040673935\n",
            "MSE Score:  0.15906548517979346\n",
            "RMSE Score:  0.39883014577611037\n",
            "R2 score : 0.79\n",
            "MAPE Score: 6633517760.52\n",
            "Decision Tree\n",
            "MAE Score:  0.39655172413793105\n",
            "MSE Score:  0.43103448275862066\n",
            "RMSE Score:  0.6565321642986127\n",
            "R2 score : 0.42\n",
            "MAPE Score: 15.37\n",
            "Polynomial Regression\n",
            "MAE Score:  2.7705632819919783\n",
            "MSE Score:  24.269814805511295\n",
            "RMSE Score:  4.926440378763483\n",
            "R2 score : -31.64\n",
            "MAPE Score: 216577781453.59\n",
            "Random Forest Regressor\n",
            "MAE Score:  0.2913793103448276\n",
            "MSE Score:  0.1967241379310345\n",
            "RMSE Score:  0.44353594885988046\n",
            "R2 score : 0.74\n",
            "MAPE Score: 15517241391.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **with Pearson Correlation Coefficient **"
      ],
      "metadata": {
        "id": "5AJUZPZUOatT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import statsmodels.api as sm\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/students_responses_main.csv')\n",
        "df_org = df.copy()\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(columns= df.columns[88], inplace=True)\n",
        "df.drop(columns= df.columns[74], inplace=True)\n",
        "df.drop(columns= df.columns[58], inplace=True)\n",
        "df.drop(columns = df.columns[12:50], inplace = True)\n",
        "df.drop(columns= df.columns[10], inplace=True)\n",
        "df.drop(columns= df.columns[8], inplace=True)\n",
        "df.drop(columns= df.columns[7], inplace=True)\n",
        "df.drop(columns= df.columns[0], inplace=True)\n",
        "\n",
        "# Data cleaning\n",
        "df['Kindly choose your current semester.'] = df['Kindly choose your current semester.'].str.replace('2 Semester','1 Semester',regex=True).str.replace('3 Semester','2 Semester',regex=True).str.replace('4 Semester','3 Semester',regex=True).str.replace('5 Semester','4 Semester',regex=True).str.replace('6 Semester','5 Semester',regex=True).str.replace('7 Semester','6 Semester',regex=True).str.replace('8 Semester','7 Semester',regex=True)\n",
        "\n",
        "df['Your matric marks percentage?'] = np.where(df['Your matric marks percentage?'] > 100,\n",
        "                                               df['Your matric marks percentage?'] * 100 / 1100,\n",
        "                                               df['Your matric marks percentage?'])\n",
        "\n",
        "df[\"Your Fsc/Ics marks percentage?\"] = np.where(df[\"Your Fsc/Ics marks percentage?\"] > 100,\n",
        "                                                df[\"Your Fsc/Ics marks percentage?\"]* 100/1100,\n",
        "                                                df[\"Your Fsc/Ics marks percentage?\"])\n",
        "\n",
        "df.round(decimals=2)\n",
        "\n",
        "# Remove outliers based on IQR\n",
        "df = df.select_dtypes(include=['number'])\n",
        "Q1 = df.quantile(0.15)\n",
        "Q3 = df.quantile(0.85)\n",
        "IQR = Q3 - Q1\n",
        "df = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "df.describe()\n",
        "\n",
        "# Function to factorize object columns\n",
        "def factorize_fun(data):\n",
        "    obj_cols = data.loc[:, data.dtypes == object].columns\n",
        "    for col in obj_cols:\n",
        "        data[col] = pd.factorize(data[col])[0] + 1\n",
        "    return data\n",
        "\n",
        "df = factorize_fun(df)\n",
        "\n",
        "# Handle missing data using KNN Imputation\n",
        "def knn_null(df):\n",
        "    imputer = KNNImputer(n_neighbors=2)\n",
        "    df1 = imputer.fit_transform(df)\n",
        "    df2 = pd.DataFrame(df1, columns = df.columns)\n",
        "    return df2\n",
        "\n",
        "df = knn_null(df)\n",
        "\n",
        "# Normalize the data\n",
        "def normalize(df):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(df)\n",
        "    return data_scaled\n",
        "\n",
        "# Apply Log Transformation to the features and target\n",
        "df = df.applymap(lambda x: np.log(x + 1) if isinstance(x, (int, float)) and x > 0 else x)  # Log transform for all numeric values\n",
        "df['Please mention your Previous Semester GPA?'] = np.log(df['Please mention your Previous Semester GPA?'] + 1)\n",
        "\n",
        "# Correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Split the data\n",
        "X = df.drop(columns=['Please mention your Previous Semester GPA?'])\n",
        "X = normalize(X)\n",
        "\n",
        "y = df['Please mention your Previous Semester GPA?']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=4)\n",
        "\n",
        "# Define function to calculate PCC\n",
        "def pearson_correlation_coefficient(y_true, y_pred):\n",
        "    return np.corrcoef(y_true, y_pred)[0, 1]\n",
        "\n",
        "# Define function to calculate MAPE\n",
        "def mean_absolute_percentage_error(y_true, y_pred, clip_threshold=1.0):\n",
        "    # Clip the values in y_true to avoid division by very small numbers (close to 0)\n",
        "    y_true_clipped = np.clip(y_true, clip_threshold, np.inf)  # Clip values below `clip_threshold`\n",
        "    return np.mean(np.abs((y_true_clipped - y_pred) / y_true_clipped)) * 100\n",
        "\n",
        "# Linear Regression using statsmodels (OLS)\n",
        "print(\"OLS Linear Regression\")\n",
        "model = sm.OLS(endog=y_train, exog=X_train).fit()\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Linear Regression using sklearn\n",
        "print(\"Multivariable Linear Regression\")\n",
        "regression = LinearRegression()\n",
        "model = regression.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Decision Tree Regression\n",
        "print(\"Decision Tree\")\n",
        "regressor = DecisionTreeRegressor(random_state=0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Polynomial Regression\n",
        "print(\"Polynomial Regression\")\n",
        "poly_reg = PolynomialFeatures(degree=4)\n",
        "X_poly = poly_reg.fit_transform(X_train)\n",
        "regressor = LinearRegression()\n",
        "model = regressor.fit(X_poly, y_train)\n",
        "y_pred = model.predict(poly_reg.transform(X_test))\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n",
        "# Random Forest Regressor\n",
        "print(\"Random Forest Regressor\")\n",
        "regressor = RandomForestRegressor(n_estimators=10, random_state=0)\n",
        "model = regressor.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE Score: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE Score: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE Score: \", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R2 score : %.2f\" % r2_score(y_test,y_pred))\n",
        "print(\"MAPE Score: %.2f\" % mean_absolute_percentage_error(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2yIMighMLf3",
        "outputId": "029d3cc6-d097-460d-f855-049496b49991"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-35b5d9c88b1e>:75: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: np.log(x + 1) if isinstance(x, (int, float)) and x > 0 else x)  # Log transform for all numeric values\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OLS Linear Regression\n",
            "MAE Score:  0.05245316808061698\n",
            "MSE Score:  0.004379135498727865\n",
            "RMSE Score:  0.06617503682452971\n",
            "R2 score : 0.30\n",
            "MAPE Score: 17.36\n",
            "Multivariable Linear Regression\n",
            "MAE Score:  0.01606182948776756\n",
            "MSE Score:  0.000603202897669323\n",
            "RMSE Score:  0.024560189284069514\n",
            "R2 score : 0.90\n",
            "MAPE Score: 16.01\n",
            "Decision Tree\n",
            "MAE Score:  0.03378107342033408\n",
            "MSE Score:  0.004126990259173644\n",
            "RMSE Score:  0.06424165517149791\n",
            "R2 score : 0.34\n",
            "MAPE Score: 16.34\n",
            "Polynomial Regression\n",
            "MAE Score:  0.08670118706671123\n",
            "MSE Score:  0.01763474782124966\n",
            "RMSE Score:  0.13279588781754373\n",
            "R2 score : -1.81\n",
            "MAPE Score: 18.45\n",
            "Random Forest Regressor\n",
            "MAE Score:  0.01850103711377303\n",
            "MSE Score:  0.0007251488516715618\n",
            "RMSE Score:  0.026928587999959484\n",
            "R2 score : 0.88\n",
            "MAPE Score: 16.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mCL3ZYbZOLnZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}